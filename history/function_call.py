import asyncio
import json
import sys
from typing import Optional, List, Dict, Any
from contextlib import AsyncExitStack
from datetime import datetime

from mcp import ClientSession
from mcp.client.sse import sse_client
from openai import OpenAI


class MCPClient:
    """è´Ÿè´£ç®¡ç†ä¸ MCP Server çš„è¿æ¥"""

    def __init__(self):
        self.exit_stack = AsyncExitStack()
        self.session: Optional[ClientSession] = None

    async def connect(self, server_url: str) -> ClientSession:
        """è¿æ¥åˆ° SSE æœåŠ¡å™¨å¹¶è¿”å› session"""
        streams = await self.exit_stack.enter_async_context(sse_client(url=server_url))
        self.session = await self.exit_stack.enter_async_context(ClientSession(*streams))
        await self.session.initialize()
        print("âœ… å·²åˆå§‹åŒ– SSE å®¢æˆ·ç«¯")
        return self.session

    async def list_tools(self) -> List[Dict[str, Any]]:
        """è·å–å·¥å…·åˆ—è¡¨å¹¶æ ¼å¼åŒ–"""
        response = await self.session.list_tools()
        tools = response.tools
        print("ğŸ”§ MCP Server æä¾›çš„å·¥å…·ï¼š")
        for tool in tools:
            print(f"- {tool.name}: {tool.description}")

        formatted_tools = []
        for tool in tools:
            properties = {
                param_name: {
                    "type": param_info["type"],
                    "description": param_info.get("description", param_info.get("title", ""))
                }
                for param_name, param_info in tool.inputSchema.get("properties", {}).items()
            }
            tool_dict = {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": {
                        "type": "object",
                        "properties": properties,
                        "required": tool.inputSchema.get("required", [])
                    }
                }
            }
            formatted_tools.append(tool_dict)

        print("\nğŸ“¦ è½¬æ¢åçš„å·¥å…·æ ¼å¼ï¼š")
        print(json.dumps(formatted_tools, indent=2, ensure_ascii=False))
        return formatted_tools

    async def cleanup(self):
        """å…³é—­è¿æ¥"""
        try:
            await self.exit_stack.aclose()
        except asyncio.CancelledError:
            # å¿½ç•¥ï¼Œå› ä¸ºæ˜¯æ­£å¸¸é€€å‡º
            pass

class ChatSession:
    """è´Ÿè´£èŠå¤©é€»è¾‘ä¸å·¥å…·è°ƒç”¨"""

    def __init__(self, model: str, tools: List[Dict[str, Any]], session: ClientSession):
        self.model = model
        self.tools = tools
        self.session = session
        self.messages: List[Dict[str, Any]] = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥æ‰¾å’Œäº†è§£å®æ—¶ä¿¡æ¯ã€‚"}
        ]
        self.openai_client = OpenAI(
            base_url="https://api.siliconflow.cn/v1",
            api_key="sk-fvysgovrkoqorpbqpubqfbvfkwfwqkpthtmvzsvdwfkmwpzz"  # âš ï¸ ä¸è¦ç¡¬ç¼–ç ï¼Œæ”¹ç”¨ç¯å¢ƒå˜é‡
        )

    async def process_tool_calls(self, tool_calls):
        """å¤„ç†å·¥å…·è°ƒç”¨å¹¶æ›´æ–°æ¶ˆæ¯å†å²"""
        self.messages.append({
            "role": "assistant",
            "content": None,
            "tool_calls": [
                {
                    "id": tool_call.id,
                    "type": "function",
                    "function": {
                        "name": tool_call.function.name,
                        "arguments": tool_call.function.arguments
                    }
                }
                for tool_call in tool_calls
            ]
        })

        for tool_call in tool_calls:
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments or "{}")
            print(f"\nâš™ï¸ æ¨¡å‹è¯·æ±‚è°ƒç”¨å·¥å…·: {tool_call.function.name,} å‚æ•°: {tool_call.function.arguments}")
            confirm = input("æ˜¯å¦æ‰§è¡Œè¯¥å·¥å…·? [Y/n]: ").strip().lower()                        
            # print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
            # print(f"ğŸ“¥ å‚æ•°: {json.dumps(tool_args, indent=2, ensure_ascii=False)}")
            if confirm in ("y", "yes", ""):
                pass
            else:
                print("âŒ å·¥å…·è°ƒç”¨å·²å–æ¶ˆã€‚")
                # å¯é€‰ï¼šæŠŠæ‹’ç»ä¿¡æ¯åé¦ˆç»™æ¨¡å‹
                self.messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": tool_name,
                    "content": '{"error": "user_denied", "message": "ç”¨æˆ·æ‹’ç»æ‰§è¡Œè¯¥å·¥å…·"}'
                })
                continue

            try:
                tool_response = await self.session.call_tool(tool_name, tool_args)
                if tool_response.isError:
                    error_message = tool_response.content[0].text if tool_response.content else "æœªçŸ¥é”™è¯¯"
                    print(f"âŒ å·¥å…·æ‰§è¡Œé”™è¯¯: {error_message}")
                    formatted = {"status": "error", "message": error_message}
                else:
                    result = tool_response.content[0].text if tool_response.content else ""
                    print(f"âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ:\n {result}")
                    formatted = {"status": "success", "result": result}

                self.messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": tool_name,
                    "content": json.dumps(formatted, ensure_ascii=False)
                })

            except Exception as e:
                print(f"âš ï¸ å·¥å…·è°ƒç”¨å¼‚å¸¸: {e}")
                formatted_error = {"status": "error", "message": str(e)}
                self.messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": tool_name,
                    "content": json.dumps(formatted_error, ensure_ascii=False)
                })

    async def chat_loop(self):
        """ä¸»å¯¹è¯å¾ªç¯"""
        print("ğŸ¤– æ¬¢è¿ä½¿ç”¨ AI åŠ©æ‰‹ï¼(æŒ‰ Ctrl+C é€€å‡º)")
        try:
            while True:
                user_input = input("\nç”¨æˆ·: ").strip()
                if not user_input:
                    continue
                self.messages.append({"role": "user", "content": user_input})

                print("\nAI: ", end="", flush=True)
                done = False

                # --- å·¥å…·è§¦å‘è§„åˆ™ ---
                if user_input.startswith("/rag "):
                    text = user_input.replace("/rag ", "")
                    print("æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡çŒ®")
                    # await self.handle_tool_calls([{
                    #     "id": "local-save",
                    #     "name": "string_to_file",
                    #     "arguments": {"text": text}
                    # }])

                while not done:
                    stream = self.openai_client.chat.completions.create(
                        model=self.model,
                        messages=self.messages,
                        tools=self.tools,
                        stream=True,
                    )

                    full_response = ""
                    final_tool_calls = {}

                    for chunk in stream:
                        delta = chunk.choices[0].delta

                        # æ­£å¼è¾“å‡º
                        if delta.content:
                            full_response += delta.content
                            print(delta.content, end="", flush=True)

                        # æ€ç»´é“¾ï¼ˆreasoningï¼‰
                        # æ­£å¸¸ä¸éœ€è¦ä¿å­˜ reasoning_content åˆ° messagesï¼Œåªåœ¨éœ€è¦æ—¶ä½œä¸ºè°ƒè¯•/å±•ç¤ºæ—¥å¿—ä¿å­˜ã€‚
                        if getattr(delta, "reasoning_content", None):
                            print(delta.reasoning_content, end="", flush=True)

                        # summary æ•è·
                        if getattr(delta, "summary", None):
                            print(delta.summary, flush=True)

                        # å·¥å…·è°ƒç”¨æ‹¼æ¥
                        for tool_call in delta.tool_calls or []:
                            idx = tool_call.index
                            if idx not in final_tool_calls:
                                final_tool_calls[idx] = tool_call
                            else:
                                final_tool_calls[idx].function.arguments += tool_call.function.arguments

                    if final_tool_calls:
                        await self.process_tool_calls(list(final_tool_calls.values()))
                        continue
                    else:
                        self.messages.append({"role": "assistant", "content": full_response})
                        done = True

        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            self._save_session()

    def _save_session(self):
        """ä¿å­˜å¯¹è¯å†å²åˆ° JSON æ–‡ä»¶"""
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        # filename = f"chat_history_{ts}.json"
        filename = f"chat_history.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(self.messages, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å·²ä¿å­˜å¯¹è¯å†å²åˆ° {filename}")


async def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: uv run client.py <SSE MCPæœåŠ¡å™¨çš„URL>")
        sys.exit(1)

    client = MCPClient()
    try:
        session = await client.connect(sys.argv[1])
        tools = await client.list_tools()
        chat = ChatSession("Qwen/Qwen3-8B", tools, session)
        await chat.chat_loop()
    finally:
        await client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
